{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f67a52f-b58f-41f7-9088-7a81cd447284",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Hare Krishna/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2024-5-28 Python-3.11.4 torch-2.3.0+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5n summary: 213 layers, 1867405 parameters, 0 gradients, 4.5 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Check if CUDA is available and load model accordingly\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load YOLOv5 model with half precision\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5n', pretrained=True).to(device).half()\n",
    "\n",
    "def detect_objects(image):\n",
    "    # Resize image for faster processing (e.g., 640x480)\n",
    "    resized_image = cv2.resize(image, (640, 480))\n",
    "\n",
    "    # Convert image to FP16 and to tensor\n",
    "    img_tensor = torch.from_numpy(resized_image).permute(2, 0, 1).unsqueeze(0).to(device).half()\n",
    "\n",
    "    # Perform object detection\n",
    "    with torch.no_grad():\n",
    "        results = model(img_tensor)\n",
    "\n",
    "    # Extract bounding boxes, confidences, and class IDs from the results tensor\n",
    "    detections = results[0].cpu().numpy()  # Convert to numpy array\n",
    "    boxes = detections[:, :4]\n",
    "    confidences = detections[:, 4]\n",
    "    class_ids = detections[:, 5].astype(int)\n",
    "\n",
    "    # Apply Non-Maximum Suppression (NMS)\n",
    "    indices = cv2.dnn.NMSBoxes(boxes.tolist(), confidences.tolist(), score_threshold=0.5, nms_threshold=0.4)\n",
    "    indices = np.array(indices).flatten()  # Flatten the list of indices\n",
    "\n",
    "    return boxes, confidences, class_ids, indices\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(1)  # Use 0 for the default webcam\n",
    "\n",
    "# Check if the webcam is opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open webcam\")\n",
    "else:\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Error: Failed to capture frame\")\n",
    "            break\n",
    "\n",
    "        boxes, confidences, class_ids, indices = detect_objects(frame)\n",
    "        font = cv2.FONT_HERSHEY_PLAIN\n",
    "        for i in indices:\n",
    "            x1, y1, x2, y2 = boxes[i]\n",
    "            if not np.isnan(x1) and not np.isnan(y1) and not np.isnan(x2) and not np.isnan(y2):\n",
    "                x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)  # Convert to integers\n",
    "                label = model.names[class_ids[i]]  # Get class name\n",
    "                color = (0, 255, 0)  # Green color for bounding box\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "                cv2.putText(frame, label, (x1, y1 - 10), font, 1, color, 2)\n",
    "\n",
    "        cv2.imshow(\"Webcam\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce73c82-3a4d-4f9c-9f77-14ce418d2571",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2a8d15-10cf-4828-a943-d51f588c6f6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
